{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "data_path = \"/opt/ml/data\"\n",
    "\n",
    "train_path = os.path.join(data_path, \"train\")\n",
    "val_path = os.path.join(data_path, \"val\")\n",
    "test_path = os.path.join(data_path, \"test\")\n",
    "\n",
    "\n",
    "# DATA_PATH: \"/opt/ml/data/\"\n",
    "# DATASET: \"TACO\"\n",
    "# IMG_SIZE: 224\n",
    "# AUG_TRAIN: \"simple_augment_train\"\n",
    "# AUG_TEST: \"simple_augment_test\"\n",
    "# AUG_TRAIN_PARAMS: \n",
    "# BATCH_SIZE: 64\n",
    "# EPOCHS: 100\n",
    "# VAL_RATIO: 0.0\n",
    "# INIT_LR: 0.1\n",
    "# FP16: True\n",
    "\n",
    "# train_dataset, val_dataset, test_dataset = get_dataset(\n",
    "#         data_path=config[\"DATA_PATH\"],\n",
    "#         dataset_name=config[\"DATASET\"],\n",
    "#         img_size=config[\"IMG_SIZE\"],\n",
    "#         val_ratio=config[\"VAL_RATIO\"],\n",
    "#         transform_train=config[\"AUG_TRAIN\"],\n",
    "#         transform_test=config[\"AUG_TEST\"],\n",
    "#         transform_train_params=config[\"AUG_TRAIN_PARAMS\"],\n",
    "#         transform_test_params=config.get(\"AUG_TEST_PARAMS\"),\n",
    "#     )\n",
    "\n",
    "transform_train = \"simple_augment_train\"\n",
    "transform_test = \"simple_augment_test\"\n",
    "dataset_name = \"TACO\"\n",
    "img_size = 224\n",
    "transform_train_params = dict()\n",
    "transform_test_params = dict()\n",
    "\n",
    " # preprocessing policies\n",
    "transform_train = getattr(\n",
    "    __import__(\"src.augmentation.policies\", fromlist=[\"\"]),\n",
    "    transform_train,\n",
    ")(dataset=dataset_name, img_size=img_size, **transform_train_params)\n",
    "\n",
    "\n",
    "transform_test = getattr(\n",
    "    __import__(\"src.augmentation.policies\", fromlist=[\"\"]),\n",
    "    transform_test,\n",
    ")(dataset=dataset_name, img_size=img_size, **transform_test_params)\n",
    "\n",
    "\n",
    "train_dataset = ImageFolder(root=train_path, transform=transform_train)\n",
    "val_dataset = ImageFolder(root=val_path, transform=transform_test)\n",
    "test_dataset = ImageFolder(root=test_path, transform=transform_test)\n",
    "\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dl, val_dl, test_dl = create_dataloader(data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer = TorchTrainer(\n",
    "    model=model_instance,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    scaler=scaler,\n",
    "    device=device,\n",
    "    model_path=model_path,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "test_loss, test_f1, test_acc = trainer.test(\n",
    "        model=model_instance, test_dataloader=val_dl if val_dl else test_dl\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "\n",
    "model_instance = torchvision.models.mobilenet_v3_large(pretrained=True, width_mult=1.0,  reduced_tail=False, dilated=False)\n",
    "\n",
    "model_instance.load_state_dict(\n",
    "            torch.load(\"/opt/ml/code/exp/latest2/best.pt\")\n",
    "        )\n",
    "\n",
    "save_path = os.path.join(\"/opt/ml/code/model\", \"mobilenet_v3_best.pt\")\n",
    "torch.save(model_instance, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision.models.mobilenetv3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11577/379633544.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/opt/ml/code/model\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mobilenet_v3_best.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/eval/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    582\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/eval/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision.models.mobilenetv3'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "save_path = os.path.join(\"/opt/ml/code/model\", \"mobilenet_v3_best.pt\")\n",
    "\n",
    "model = torch.load(save_path)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e31c68abf1d5dd3f9e2269f23eadf1b199587e56c0618a30760176a65ebfcab4"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('lightweight': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
